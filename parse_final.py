import re
import json
from difflib import SequenceMatcher

def normalize_text(text):
    """Chuáº©n hÃ³a text Ä‘á»ƒ so sÃ¡nh"""
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text.strip()

def normalize_phone(phone):
    """Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i"""
    return re.sub(r'\D', '', phone)

def similarity(a, b):
    """TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a 2 chuá»—i"""
    return SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()

def extract_address_core(content):
    """TrÃ­ch xuáº¥t pháº§n Ä‘á»‹a chá»‰ cá»‘t lÃµi tá»« content"""
    # Loáº¡i bá» pháº§n mÃ´ táº£ tÃ¬nh tráº¡ng thÆ°á»ng gáº·p
    clean_content = re.sub(r'\(.*?\)', '', content) # Bá» ngoáº·c
    clean_content = re.sub(r'\d+\s*(ngÆ°á»i|em|bÃ©|chÃ¡u|Ä‘á»©a|con|lá»›n|nhá»)', '', clean_content, flags=re.IGNORECASE)
    
    # Láº¥y pháº§n Ä‘áº§u (thÆ°á»ng lÃ  Ä‘á»‹a chá»‰)
    words = clean_content.split()
    if len(words) > 15:
        address = ' '.join(words[:15])
    else:
        address = clean_content
    return normalize_text(address)

def is_duplicate(case1, case2, phone_threshold=0.5, address_threshold=0.8):
    """Kiá»ƒm tra 2 case cÃ³ trÃ¹ng láº·p khÃ´ng"""
    # Check phone numbers
    phones1 = set([normalize_phone(p) for p in case1['phones']])
    phones2 = set([normalize_phone(p) for p in case2['phones']])
    
    if phones1 and phones2:
        common_phones = phones1.intersection(phones2)
        if len(common_phones) > 0:
            return True
    
    # Check address similarity
    addr1 = extract_address_core(case1['content'])
    addr2 = extract_address_core(case2['content'])
    
    if addr1 and addr2 and len(addr1) > 8 and len(addr2) > 8:
        sim = similarity(addr1, addr2)
        if sim >= address_threshold:
            return True
    
    return False

def merge_duplicates(cases):
    """Gá»™p cÃ¡c case trÃ¹ng láº·p, giá»¯ láº¡i case cÃ³ priority cao nháº¥t (PhiÃªn báº£n tá»‘i Æ°u)"""
    priority_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
    
    # 1. NhÃ³m cÃ¡c case theo Area Ä‘á»ƒ giáº£m pháº¡m vi so sÃ¡nh
    cases_by_area = {}
    for case in cases:
        area = case['area']
        if area not in cases_by_area:
            cases_by_area[area] = []
        cases_by_area[area].append(case)
        
    unique_cases = []
    
    # 2. Xá»­ lÃ½ tá»«ng nhÃ³m Area
    for area, area_cases in cases_by_area.items():
        # Sort theo content Ä‘á»ƒ cÃ¡c case giá»‘ng nhau náº±m gáº§n nhau
        area_cases.sort(key=lambda x: x['content'])
        
        skip_indices = set()
        
        for i in range(len(area_cases)):
            if i in skip_indices:
                continue
                
            current_case = area_cases[i]
            duplicates = [current_case]
            
            # Chá»‰ so sÃ¡nh vá»›i 20 case tiáº¿p theo (vÃ¬ Ä‘Ã£ sort)
            # Äiá»u nÃ y giáº£m Ä‘á»™ phá»©c táº¡p tá»« O(N^2) xuá»‘ng O(N*K)
            for j in range(i + 1, min(i + 20, len(area_cases))):
                if j in skip_indices:
                    continue
                    
                if is_duplicate(current_case, area_cases[j]):
                    duplicates.append(area_cases[j])
                    skip_indices.add(j)
            
            # Merge logic
            # Chá»n case cÃ³ priority cao nháº¥t
            best_case = min(duplicates, key=lambda c: priority_order.get(c['priority'], 99))
            
            # Merge phones
            all_phones = set()
            for dup in duplicates:
                all_phones.update(dup['phones'])
            best_case['phones'] = sorted(list(all_phones))[:5]
            
            # Merge content (láº¥y cÃ¡i dÃ i nháº¥t)
            longest_content = max(duplicates, key=lambda x: len(x['content']))['content']
            best_case['content'] = longest_content
            
            unique_cases.append(best_case)
            
    return unique_cases

def parse_rescue_data_final(input_file):
    """Parse dá»¯ liá»‡u cá»©u há»™ hoÃ n thiá»‡n"""
    
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    raw_cases = []
    current_id = 1
    phone_pattern = r'0[\d\s\.]{8,}'
    
    # Danh sÃ¡ch khu vá»±c Má» Rá»˜NG
    area_keywords = {
        # Nha Trang & VÃ¹ng ven
        'VÄ©nh Tháº¡nh': 'VÄ©nh Tháº¡nh',
        'Chá»£ Ga': 'VÄ©nh Tháº¡nh',
        'PhÃº BÃ¬nh': 'VÄ©nh Tháº¡nh',
        'VÄ©nh Ngá»c': 'VÄ©nh Ngá»c',
        'LÆ°Æ¡ng Äá»‹nh Cá»§a': 'VÄ©nh Ngá»c',
        'XuÃ¢n Láº¡c': 'VÄ©nh Ngá»c',
        'VÄ©nh Hiá»‡p': 'VÄ©nh Hiá»‡p',
        'VÄ©nh ThÃ¡i': 'VÄ©nh ThÃ¡i',
        'ThÃ¡i ThÃ´ng': 'VÄ©nh ThÃ¡i',
        'VÄ©nh Trung': 'VÄ©nh Trung',
        'VÄ©nh PhÆ°Æ¡ng': 'VÄ©nh PhÆ°Æ¡ng',
        'VÄ©nh Háº£i': 'VÄ©nh Háº£i',
        'Báº¯c Nha Trang': 'Báº¯c Nha Trang',
        'ÄÆ°á»ng 23/10': 'ÄÆ°á»ng 23/10',
        'Cáº§u BÃ¨': 'Cáº§u BÃ¨',
        'Cáº§u Dá»©a': 'Cáº§u Dá»©a',
        'Cáº§u KÃ©': 'Cáº§u KÃ©',
        'Cáº§u Gá»—': 'Cáº§u Gá»—',
        'CÃ¢y Dáº§u ÄÃ´i': 'CÃ¢y Dáº§u ÄÃ´i',
        'GÃ² CÃ¢y Sung': 'GÃ² CÃ¢y Sung',
        'PhÃº NÃ´ng': 'PhÃº NÃ´ng',
        'Bá»‡nh Viá»‡n ÄÆ°á»ng Sáº¯t': 'BV ÄÆ°á»ng Sáº¯t',
        'BV ÄÆ°á»ng Sáº¯t': 'BV ÄÆ°á»ng Sáº¯t',
        'Ngá»c Hiá»‡p': 'Ngá»c Hiá»‡p',
        'PhÆ°á»›c Äá»“ng': 'PhÆ°á»›c Äá»“ng',
        'Äá»“ng Muá»‘i': 'PhÆ°á»›c Long',
        
        # DiÃªn KhÃ¡nh (Chi tiáº¿t)
        'DiÃªn An': 'DiÃªn An',
        'PhÃº Ã‚n Nam': 'DiÃªn An',
        'DiÃªn ToÃ n': 'DiÃªn ToÃ n',
        'DiÃªn Thá»': 'DiÃªn Thá»',
        'DiÃªn PhÆ°á»›c': 'DiÃªn PhÆ°á»›c',
        'DiÃªn Láº¡c': 'DiÃªn Láº¡c',
        'DiÃªn SÆ¡n': 'DiÃªn SÆ¡n',
        'DiÃªn LÃ¢m': 'DiÃªn LÃ¢m',
        'DiÃªn TÃ¢n': 'DiÃªn TÃ¢n',
        'DiÃªn Äiá»n': 'DiÃªn Äiá»n',
        'DiÃªn PhÃº': 'DiÃªn PhÃº',
        'DiÃªn HÃ²a': 'DiÃªn HÃ²a',
        'BÃ¬nh KhÃ¡nh': 'DiÃªn HÃ²a',
        'DiÃªn KhÃ¡nh': 'DiÃªn KhÃ¡nh',
        'Suá»‘i Hiá»‡p': 'Suá»‘i Hiá»‡p',
        
        # KhÃ¡c
        'BÃ n Tháº¡ch': 'BÃ n Tháº¡ch',
        'VÃµ Cáº¡nh': 'VÃµ Cáº¡nh',
        'VÃµ DÃµng': 'VÃµ DÃµng',
        'XuÃ¢n SÆ¡n': 'XuÃ¢n SÆ¡n',
    }
    
    # Æ¯u tiÃªn check tá»« khÃ³a dÃ i trÆ°á»›c (VD: "DiÃªn An" trÆ°á»›c "DiÃªn")
    sorted_area_keywords = sorted(area_keywords.keys(), key=len, reverse=True)
    
    for line in lines:
        line = line.strip()
        if not line or 'Má»©c Ä‘á»™ Æ°u tiÃªn' in line or 'CHá»– NÃ€O' in line:
            continue
            
        # 1. Parse Priority (Cá»™t 1 hoáº·c tá»« khÃ³a trong cÃ¢u)
        priority = 'MEDIUM' # Default
        line_lower = line.lower()
        
        if line_lower.startswith('kháº©n cáº¥p') or 'kháº©n cáº¥p' in line_lower or 'nguy ká»‹ch' in line_lower or 'sáº¯p Ä‘áº»' in line_lower or 'vá»¡ á»‘i' in line_lower or 'tai biáº¿n' in line_lower:
            priority = 'CRITICAL'
        elif line_lower.startswith('Æ°u tiÃªn cao') or 'Æ°u tiÃªn cao' in line_lower or 'ngÆ°á»i giÃ ' in line_lower or 'tráº» em' in line_lower or 'tráº» nhá»' in line_lower or 'bÃ  báº§u' in line_lower or 'mang thai' in line_lower:
            priority = 'HIGH'
        elif line_lower.startswith('thÆ°á»ng') or 'thÆ°á»ng' in line_lower:
            priority = 'MEDIUM'
            
        # 2. Extract Phones
        phones = []
        phone_matches = re.findall(phone_pattern, line)
        for phone in phone_matches:
            clean_phone = re.sub(r'[^\d]', '', phone)
            if 9 <= len(clean_phone) <= 11:
                if len(clean_phone) == 10:
                    formatted = f"{clean_phone[:4]} {clean_phone[4:7]} {clean_phone[7:]}"
                else:
                    formatted = clean_phone
                phones.append(formatted)
        
        # 3. Clean Content
        content = line
        # Remove phones
        for p in phone_matches:
            content = content.replace(p, '')
        # Remove priority prefixes at start
        content = re.sub(r'^(Kháº©n cáº¥p|Æ¯u tiÃªn cao|ThÆ°á»ng)\s*', '', content, flags=re.IGNORECASE)
        content = re.sub(r'\s+', ' ', content).strip()
        
        if len(content) < 5: continue

        # 4. Determine Area
        area = 'KhÃ¡c'
        content_lower = content.lower()
        
        # Check area keywords
        for keyword in sorted_area_keywords:
            if keyword.lower() in content_lower:
                area = area_keywords[keyword]
                break
        
        # Fallback: Náº¿u váº«n lÃ  KhÃ¡c, thá»­ tÃ¬m "ThÃ´n X", "XÃ£ Y"
        if area == 'KhÃ¡c':
            match = re.search(r'(xÃ£|thÃ´n|phÆ°á»ng)\s+([A-ZÄ][a-zÃ -á»¹]+(\s+[A-ZÄ][a-zÃ -á»¹]+)+)', content)
            if match:
                potential_area = match.group(2)
                # Map láº¡i náº¿u cÃ³ trong DB
                for keyword in sorted_area_keywords:
                     if keyword.lower() in potential_area.lower():
                        area = area_keywords[keyword]
                        break
        
        raw_cases.append({
            "id": current_id,
            "content": content,
            "phones": phones,
            "area": area,
            "priority": priority,
            "isRescued": False
        })
        current_id += 1

    print(f"ğŸ“ Raw cases: {len(raw_cases)}")
    
    # Deduplicate
    print("ğŸ” Deduplicating...")
    unique_cases = merge_duplicates(raw_cases)
    print(f"âœ… Unique cases: {len(unique_cases)} (Removed {len(raw_cases) - len(unique_cases)})")
    
    # Re-index
    for i, case in enumerate(unique_cases, 1):
        case['id'] = i
        
    return unique_cases

# Run
print("ğŸš€ STARTING FINAL PARSE...")
data = parse_rescue_data_final('pdf_content.txt')

# Stats
area_counts = {}
priority_counts = {}
for c in data:
    area_counts[c['area']] = area_counts.get(c['area'], 0) + 1
    priority_counts[c['priority']] = priority_counts.get(c['priority'], 0) + 1

print("\nğŸ“Š PRIORITY STATS:")
for p, c in priority_counts.items():
    print(f"  {p}: {c}")

print("\nğŸ—ºï¸ AREA STATS (Top 20):")
for a, c in sorted(area_counts.items(), key=lambda x: x[1], reverse=True)[:20]:
    print(f"  {a}: {c}")

# Save
with open('rescue-app/src/data.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
print("\nğŸ’¾ Saved to rescue-app/src/data.json")
